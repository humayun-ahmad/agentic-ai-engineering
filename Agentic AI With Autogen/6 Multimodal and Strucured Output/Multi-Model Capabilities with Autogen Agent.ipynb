{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25e30511",
   "metadata": {},
   "source": [
    "# <center>Messages in Autogen v0.4</center>\n",
    "\n",
    "We can imaging messages as the way agent communicate - text our Friend.\n",
    "\n",
    "When we communicate with the agents -----> sending a message when it responds ---> it too sends a message\n",
    "\n",
    "TextMessage ImageMessage ToolMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e15f414e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_agentchat.messages import TextMessage, MultiModalMessage\n",
    "from autogen_core import Image as AGImage\n",
    "\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import requests\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "model_client = OpenAIChatCompletionClient(\n",
    "    model=os.getenv(\"GEMINI_MODEL\"),\n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
    "    api_key=google_api_key,\n",
    "    model_info={\n",
    "        \"vision\": False,\n",
    "        \"function_calling\": True,\n",
    "        \"json_output\": True,\n",
    "        \"family\": \"unknown\",\n",
    "        \"structured_output\": False\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1c86cd",
   "metadata": {},
   "source": [
    "## Simplest Type of Message - TextMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c11f0127",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = AssistantAgent(\n",
    "    name=\"GK_Agent\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"You're a helpful assistant. You're an expert in generale knowledge. If anybody is asking any question regarding generale knowledge give them the answer.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "107c28c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My duty is to be a helpful and informative AI assistant. I'm here to:\n",
      "\n",
      "*   **Provide information:** I can answer your questions on a vast range of topics, drawing from my extensive knowledge base.\n",
      "*   **Assist with tasks:** I can help you brainstorm ideas, write different kinds of creative content, summarize text, translate languages, and much more.\n",
      "*   **Engage in conversation:** I can have a natural and informative conversation with you.\n",
      "*   **Learn and improve:** I'm constantly learning and being updated to become even more helpful and accurate.\n",
      "\n",
      "In essence, my duty is to assist you in any way I can with information and by performing various language-based tasks.\n"
     ]
    }
   ],
   "source": [
    "async def test_text_message():\n",
    "    text_msg = TextMessage(content = \"what's your duty?\", source='user')\n",
    "    result = await agent.run(task=text_msg)\n",
    "    print(result.messages[-1].content)\n",
    "    \n",
    "await test_text_message()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eeb541a",
   "metadata": {},
   "source": [
    "## Multi Modal Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "82cc1e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am sorry, I cannot process images. Therefore, I cannot tell you what is in the image.\n"
     ]
    }
   ],
   "source": [
    "async def test_multi_modal():\n",
    "    response = requests.get('https://picsum.photos/id/237/200/300')\n",
    "    pil_image = Image.open(BytesIO(response.content))\n",
    "    ag_image = AGImage(pil_image)\n",
    "    \n",
    "    multi_modal_msg = MultiModalMessage(\n",
    "        content = ['What is in the image?', ag_image],\n",
    "        source='user'\n",
    "    )\n",
    "    \n",
    "    result = await agent.run(task=multi_modal_msg)\n",
    "    print(result.messages[-1].content)\n",
    "    \n",
    "await test_multi_modal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b1543e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the image, here is a detailed description of what is shown:\n",
      "\n",
      "The image is a close-up, high-angle shot of an **adorable black puppy**, which appears to be a **Labrador Retriever**.\n",
      "\n",
      "Here are some key features:\n",
      "\n",
      "*   **Subject:** A young, black puppy.\n",
      "*   **Pose:** The puppy is lying or sitting on a wooden surface and looking directly up at the camera.\n",
      "*   **Expression:** It has large, expressive, and soulful brown eyes that create a direct and engaging connection with the viewer.\n",
      "*   **Features:** The puppy has a glossy black coat, characteristic floppy ears of a retriever, and a cute, dark nose.\n",
      "*   **Background:** The puppy is on a wooden surface, like a deck or floor, with visible wood grain.\n",
      "*   **Composition:** The photo is taken from above, which emphasizes the puppy's face and its upward gaze, making it look particularly cute and innocent.\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "from PIL import Image\n",
    "\n",
    "response = requests.get('https://picsum.photos/id/237/200/300')\n",
    "\n",
    "image = Image.open(BytesIO(response.content))\n",
    "model = genai.GenerativeModel('gemini-2.5-pro')\n",
    "response = model.generate_content(\n",
    "    [\n",
    "        \"What is in the image?\",\n",
    "        image\n",
    "    ]\n",
    ")\n",
    "print(response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
